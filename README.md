# Vyoma: Generative AI-Based Image Assessed Voice Assistant

Vyoma is a multimodal AI-powered voice assistant designed to analyze images and provide detailed spoken descriptions. By integrating advanced image recognition and natural language processing technologies, Vyoma allows users to interact through voice commands while gaining insights into the visual content. The system can handle complex image analysis, including symbols, objects, and scenes, making it suitable for various applications such as accessibility tools, education, and research.

## Features

- **Image-to-Text Generation**: Automatically analyzes and describes uploaded images using Hugging Face's transformers.
- **Speech-to-Text Transcription**: Converts user voice inputs to text using OpenAI Whisper.
- **Text-to-Speech Conversion**: Transforms image descriptions into audio using gTTS.
- **Multimodal Interaction**: Supports both image upload and voice input for a seamless user experience.
- **Gradio Interface**: Provides a simple and intuitive web-based UI for interacting with Vyoma.


## Technologies Used

- **Hugging Face Transformers**: For image-to-text processing with model quantization.
- **OpenAI Whisper**: For accurate and multilingual speech-to-text transcription.
- **Gradio**: Easy-to-use interface for receiving user inputs and displaying results.
- **gTTS (Google Text-to-Speech)**: For generating audio responses from text.
- **Pillow (PIL)**: For image processing and loading.

## Installation

To run the Vyoma assistant locally, follow these steps:

1. **Clone the repository**:
   ```bash
   git clone https://github.com/surajsharma68/Vyoma-Generative-AI-Based-Image-Assessed-Voice-Assistant.git
   cd Vyoma-Generative-AI-Based-Image-Assessed-Voice-Assistant

## Demo

Watch the Vyoma demo on YouTube to see how it works in action:

[![Vyoma Demo](https://img.youtube.com/vi/D3d95ew_lx4/0.jpg)](https://youtu.be/D3d95ew_lx4)

Click on the image or [here](https://youtu.be/D3d95ew_lx4) to watch the demo.
